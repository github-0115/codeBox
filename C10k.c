

// V1，使用多进程， 多线程的模型，每个线程/进程处理一个连接， 资源占用过多， 可扩展性差  


// V2, 采用 select 的方式 ， 有句柄上限加重复初始化，效率不高
int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeval);


// V3, 采用poll方式， 无句柄上限， 但是要排查所有文件句柄状态效率不高
int poll(struct pollfd *fds, nfds_t nfds, int timeout);


// V4, 采用 epoll 方式， 只返回有状态变化的句柄，效率高， 但是只支持linux
int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);



/**
经历过上面的 4 个版本，内核的处理性能基本上已经发挥到最高了，已经可以完美的解决 C10K 
的问题了，那么假如并发大过C10K， 怎么解决呢？？ 要么就不断的堆服务器，要么就想办法提高
单机服务器的处理性能

这里有一个关键性的问题， 究竟 select/poll/epoll 的方式 跟 多进程/多线程 有什么关系？？
我的理解是， select/poll/epoll 的方式是把 IO(网络连接) 的句柄放到了内核里面去，用内核
去 监控/调用 相关的句柄， 最终处理句柄的逻辑还是靠 多线程 的，这三种方式只是处理句柄的
形式不同，所以导致性能不同 

我们分析一下性能的瓶颈主要在哪里？
1， 进程/线程 作为处理单元太厚重了
2， 系统调度的代价太高了
**/



我们应该减少 进程/线程 的数量， 数量减少了， 自然也就减少了 它们 的调度了， 那么性能就会提高
所以我们可以考虑从 内核态线程 转变为  用户态线程， 类似说 我们做一个 用户态的线程栈，每个栈就是
一个线程， 然后把 用户连接/用户逻辑 都装到栈里面去， 让一个线程去处理多个任务，这样可以依据各个
栈的运行压力，情况去 协调/分配 不同的任务，使用他们之间平衡处理，既减少了线程的产生，又能达到系统
均衡处理的效果 


 


